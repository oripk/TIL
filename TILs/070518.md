#텐서플로우 첫걸음

## 모델 만들기

  1. 특성 정의 및 특성 열 구성
    데이터의 유형
      - 범주형 데이터 : 텍스트로 이루어진 데이터
      - 수치 데이터 : 정수 도는 부동 소수점 숫자이며 숫자로 취급사려는 데이터
    텐서플로우에서는 특성의 데이터 유형을 지정할 때 특성 열이라는 구조체를 사용한다. 특성열은 특성 데이터에 대한 설명만 저장하며 특성 데이터 자체는 포함하지 않습니다.

<pre><code>
    # Define the input feature: total_rooms.
    my_feature = california_housing_dataframe[["total_rooms"]]

    # Configure a numeric feature column for total_rooms.
    feature_columns = [tf.feature_column.numeric_column("total_rooms")]
</code></pre>
  2. 타겟 정의
  3. LinearRegressor 구성 : 아래 예제에서는 선형 회귀 모델 구성 및 미니 배치 확률적 경사하강법을 구현하는 GradientDescentOptimizer를 사용하여 이 모델을 학습시킬 것입니다. learning_rate인수는 경사단계의 크기를 조절합니다.
<pre><code>
  # Use gradient descent as the optimizer for training the model.
  my_optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.0000001)
  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)

  # Configure the linear regression model with our feature columns and optimizer.
  # Set a learning rate of 0.0000001 for Gradient Descent.

  linear_regressor = tf.estimator.LinearRegressor(
  feature_columns=feature_columns,
  optimizer=my_optimizer
)
</code></pre>

  4. 입력 함수 정의 : 텐서플로우에 데이터 전처리 방법 및 모델 학습 중의 일괄 처리, 셔플, 반복 방법을 알려주는 입력 함수를 정의해야 한다.

    먼저, pandas 특성 데이터를 Numpy 배열의 dict로 변환
    텐서플로우의 Dataset API를 사용하여 이 데이터로부터 데이터 세트 개체를 생서앟고 batch_size 크기의 배치로 나누어 지정한 세대 수만큼 반복합니다.이후 shuffle을 True로 설정하면 학습 중에 데이터가 모델에 무작위로 전달되도록 데이터가 뒤섞입니다. buffer_size인수는 shuffle에서 무작위로 추출할 데이터 세트의 크기를 지정합니다.

  5. 모델 학습 : linear_regressor로부터 train()을 호출하여 모델을 학습 시킬수 있습니다.

  6. 모델 평가 : 모델이 학습 중 학습 데이터에 얼마나 맞춰졌는지 확인하기 위해 학습 데이터로 예측을 실행하겠습니다.

<pre><code>
  # Create an input function for predictions.
  # Note: Since we're making just one prediction for each example, we don't
  # need to repeat or shuffle the data here.
  prediction_input_fn =lambda: my_input_fn(my_feature, targets, num_epochs=1, shuffle=False)

  # Call predict() on the linear_regressor to make predictions.
  predictions = linear_regressor.predict(input_fn=prediction_input_fn)

  # Format predictions as a NumPy array, so we can calculate error metrics.
  predictions = np.array([item['predictions'][0] for item in predictions])

  # Print Mean Squared Error and Root Mean Squared Error.
  mean_squared_error = metrics.mean_squared_error(predictions, targets)
  root_mean_squared_error = math.sqrt(mean_squared_error)
  print("Mean Squared Error (on training data): %0.3f" % mean_squared_error)
  print("Root Mean Squared Error (on training data): %0.3f" % root_mean_squared_error)
</code></pre>

  위 코드에서 RMSE의 타겟의 최소값과 최대 값의 차를 비교해보면, 오차범위를 어느정도 파악할 수 있다. 이를 줄이기 위해서는 몇가지 일을 해야 한다. 먼저 얼마나 예측을 잘하는지 알기 위해 통계를 조사해야 한다. 또 이를 좀 더 보기 편하도록 그래프로 표현하는 일이 필요하다. 이를 통해 좀 더 오차범위가 작은 모델을 설정하기 위한 방향성을 잡게 될 것이다.

## 모델 초매개변수 조정
---
학습 기간을 나누어 각 기간 별로 모델의 개선정도를 살펴볼 수 있습니다. 해당 함수에서는 각 기간에 대한 학습 손실을 계산하고 그래프로 출력하므로서 모델이 수렴되는 시점을 판단하거나 반복이 더 필요함을 확인 할 수 있습니다.


# 합성 특성과 이상점
---
 문제는 도저히 뭔말인지 모르겠어서 못 풀겠습니다. ㅠㅠ 아직 수련이 필요하네요
