# 일반화
## 과적합
  머신러닝으로 주어진 데이터 학습이 매우 잘 되어 예측이 100퍼센트인 경우 우리는 이를 과적합이라고 부를 수 있다.

  과적합이라고 말하는 이유는 현재 상태에서 새로운 데이터를 넣었을 때 100퍼센트 예측을 맞출 수 없습니다.

  학습을 했을 때 우리가 원하는 것은 학습 후 새로운 것에 대한 예측이 어느정도 맞아야 된다는 것입니다. 하지만 주어진 데이터에 국한해서 이를 100퍼센트 학습이 된다면 오차가 커지는 일이 발생할 수 도 있습니다.

4세기의 수도사이자 철학자인 William of Occam은 단순성을 좋아했습니다. 그는 과학자는 복잡한 것보다 간단한 공식이나 이론을 선택해야 한다고 생각했습니다. Occam의 면도날 법칙을 머신러닝 용어로 표현하면 다음과 같습니다.

ML 모델이 덜 복잡할수록 샘플의 특성 때문이 아니어도 좋은 경험적 결과를 얻을 가능성이 높습니다.

## 모델의 적합성 확인법

- 이론적인 측면 :
  + 흥미로운 분야 : 일반화 이론
  + 모델의 단순성/복잡성 측정 아이디어를 기반으로 함
- 직관 : 오컴의 면도날 원칙의 형식화
-경험적인 측면 :
  + 질문 : 모델이 새로운 데이터 샘플에 효과적으로 작동하나요?
  + 평가 : 새로운 데이터 샘플을 얻습니다.
  + 모델이 테스트 세트에서 효과적으로 작동하면 다음과 같은 경우 새로운 데이터에도 잘 작동할 것이라고 추정할 수 있음
    - 테스트 세트가 충분히 큰 경우
    - 테스트 세트를 반복적으로 사용하지 않는 경우

## ML세부사항
위의 경우 모두 기본적으로 다음 세 가지를 가정합니다.

1. 분포에서 독립적이고 동일한 방식으로(i.i.d.) 임의로 예를 추출합니다.
1. 분포가 정상성을 보이며 시간이 지나도 변하지 않습니다
1. 학습, 유효성 검사 및 테스트 세트를 항상 같은 분포에서 추출합니다.

##학습 및 평가 세트
데이터 세트가 하나뿐이라면 어떻게 하나요? 다음과 같이 두 세트로 분할합니다.
- 학습 세트
- 테스트 세트

기억해야 할 유의사항: 테스트 데이터로 학습하지 않기 손실이 이상할 정도로 적은가요?기뻐하기는 이릅니다. 실수로 테스트 데이터로 학습하진 않았는지 확인해 보세요.

## 검증

데이터 세트를 학습 세트 + 테스트 세트로 구분하는 것이 아니라, 학습 세트 + 검증 세트 + 테스트 세트로 구분하여 학습세트로 학습 한 이후 검증 세트로만 계속 테스트 해서 초매개변수를 조작하는 이러한 과정을 통하면 과적합 가능성을 크게 낮출 수 있습니다. 최종 테스트 할 때만 테스트 세트를 사용 하는 것이지요.
